{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle \n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MediaPipe Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MediaPipe's hands module for hand detection and landmark estimation\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Initialize the Hands object from MediaPipe\n",
    "# - static_image_mode=True: Indicates that the input will be static images (not video stream)\n",
    "# - min_detection_confidence=0.3: Minimum confidence level required to detect a hand\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data and Labels Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset'\n",
    "dataset = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract landmarks coordinates and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tarahan IT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "# Loop through each directory (representing each class) inside the dataset folder\n",
    "for directory in os.listdir(data_dir):\n",
    "    path = os.path.join(data_dir, directory)  # Construct the full path for the current class directory\n",
    "\n",
    "    # Loop through each image file in the current class directory\n",
    "    for img_path in os.listdir(path):\n",
    "        normalized_landmarks = []  # List to store normalized x, y coordinates\n",
    "        x_coordinates, y_coordinates = [], []  # Temporary lists for x and y coordinates\n",
    "\n",
    "        # Read the image and convert it from BGR to RGB format (required by MediaPipe)\n",
    "        image = cv2.imread(os.path.join(path, img_path))\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the image to detect hands using MediaPipe's hand processing method\n",
    "        processed_image = hands.process(image_rgb)\n",
    "\n",
    "        # Get the hand landmarks (if any hand is detected in the image)\n",
    "        hand_landmarks = processed_image.multi_hand_landmarks\n",
    "\n",
    "        if hand_landmarks:  # If hand landmarks are found\n",
    "            for hand_landmark in hand_landmarks:\n",
    "                landmark_coordinates = hand_landmark.landmark  # Get individual landmark coordinates\n",
    "\n",
    "                # Extract the x and y coordinates of all landmarks\n",
    "                for coordinates in landmark_coordinates:\n",
    "                    x_coordinates.append(coordinates.x)\n",
    "                    y_coordinates.append(coordinates.y)\n",
    "\n",
    "                # Find the minimum x and y values to normalize the coordinates\n",
    "                min_x, min_y = min(x_coordinates), min(y_coordinates)\n",
    "\n",
    "                # Normalize the landmarks by subtracting the minimum x and y values\n",
    "                for coordinates in landmark_coordinates:\n",
    "                    normalized_x = coordinates.x - min_x\n",
    "                    normalized_y = coordinates.y - min_y\n",
    "                    normalized_landmarks.extend((normalized_x, normalized_y))  # Add normalized values to the list\n",
    "\n",
    "            # Append the normalized landmarks to the dataset\n",
    "            dataset.append(normalized_landmarks)\n",
    "\n",
    "            # Append the label (class name) for the current directory\n",
    "            labels.append(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open (or create) a file called 'extracted_landmarks.pickle' in write-binary mode\n",
    "with open(\"./extracted_landmarks.pickle\", \"wb\") as f:\n",
    "    # Save the 'dataset' and 'labels' as a dictionary using pickle for later use\n",
    "    pickle.dump({\"dataset\": dataset, \"labels\": labels}, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
